{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Keras imports\n",
    "import tensorflow.keras.preprocessing as preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_path = os.listdir(\"../Data/Images\")\n",
    "not_path.remove(\".DS_Store\") #if it's still in there, it likes to pop up from time to time\n",
    "path_to_data = \"../Data\"\n",
    "\n",
    "test_path = os.path.join(data_path, 'test_images')\n",
    "train_path = os.path.join(data_path, 'train_images')\n",
    "val_path = os.path.join(data_path, 'val_images')\n",
    "\n",
    "data_path = os.path.join('..', 'Data')\n",
    "images_path = os.path.join(data_path, 'Images')\n",
    "image_folders = os.listdir(images_path)\n",
    "test_folders = os.listdir(test_path)\n",
    "train_folders = os.listdir(train_path)\n",
    "val_folders = os.listdir(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pugs, goldens, and pembrokes (AKA corgis)\n",
    "train_dir = \"../Data/ExModeling_train\"\n",
    "test_dir = \"../Data/ExModeling_test\"\n",
    "val_dir = \"../Data/ExModeling_val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emphasis on simple, not even using validation data\n",
    "fsm_train_dir = \"../Data/FSMimgs\"#only contains 'bluetick' and 'boxer' breeds\n",
    "fsm_train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        fsm_train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "fsm_train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsm_model = models.Sequential()\n",
    "fsm_model.add(layers.Dense(64, input_shape = (150, 150, 3)))\n",
    "fsm_model.add(layers.Flatten())\n",
    "fsm_model.add(layers.Dense(2, activation = 'softmax'))\n",
    "fsm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fsm_model.fit_generator(train_generator, steps_per_epoch=100, epochs=5)\n",
    "#neted a training accuracy of 0.4688, somehow less than half with two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy param tuning\n",
    "img_size = 128\n",
    "bch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 664 images belonging to 5 classes.\n",
      "Found 145 images belonging to 5 classes.\n",
      "Found 141 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator = img_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=bch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = img_gen.flow_from_directory(\n",
    "    val_dir, \n",
    "    target_size=(img_size, img_size), \n",
    "    color_mode='grayscale',\n",
    "    batch_size=bch_size, \n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = img_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=bch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 14:43:03.797093 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0810 14:43:03.858423 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0810 14:43:03.867154 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0810 14:43:03.901729 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0810 14:43:04.283535 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0810 14:43:04.296184 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#refrenced material: https://github.com/learn-co-students/dsc-image-classification-lab-sea01-dtsc-ft-051120/tree/solution\n",
    "#even has the same dataset, that's what I get for using the first google result of 'kaggle dog image dataset'\n",
    "#model 1: 3 dogs, Dense and Convid2D, img_size = 128\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.Dense(128, activation='relu'))\n",
    "model_1.add(layers.Dense(3, activation='softmax'))#output layer w/ softmax\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 14:44:43.136464 4631838144 deprecation.py:323] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0810 14:44:43.294936 4631838144 deprecation_wrapper.py:119] From /Users/adamroth/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 1.0545 - acc: 0.4389 - val_loss: 1.0658 - val_acc: 0.4286\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 60s 601ms/step - loss: 0.8852 - acc: 0.6138 - val_loss: 0.9146 - val_acc: 0.5714\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 45s 450ms/step - loss: 0.7634 - acc: 0.6784 - val_loss: 0.9709 - val_acc: 0.4286\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 0.6736 - acc: 0.7257 - val_loss: 1.0234 - val_acc: 0.4286\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 56s 564ms/step - loss: 0.6076 - acc: 0.7526 - val_loss: 0.9976 - val_acc: 0.4286\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 49s 493ms/step - loss: 0.5093 - acc: 0.8094 - val_loss: 1.0799 - val_acc: 0.5714\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 0.4053 - acc: 0.8505 - val_loss: 1.1888 - val_acc: 0.5714\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 47s 475ms/step - loss: 0.3073 - acc: 0.8948 - val_loss: 1.4171 - val_acc: 0.5714\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 45s 452ms/step - loss: 0.2107 - acc: 0.9383 - val_loss: 1.1346 - val_acc: 0.5714\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 0.1445 - acc: 0.9649 - val_loss: 1.8940 - val_acc: 0.5714\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added pomeranians and saluki for more classes, added more neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dense(64, activation='relu'))\n",
    "model_2.add(layers.Dense(128, activation='relu'))\n",
    "model_2.add(layers.Dense(256, activation='relu'))\n",
    "model_2.add(layers.Dense(5, activation='softmax'))#output layer w/ softmax, changed nodes to 5, =n\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 71s 707ms/step - loss: 1.5879 - acc: 0.2458 - val_loss: 1.6248 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 1.4926 - acc: 0.3547 - val_loss: 1.5292 - val_acc: 0.5833\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 1.4138 - acc: 0.3906 - val_loss: 1.4466 - val_acc: 0.4167\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 57s 568ms/step - loss: 1.3638 - acc: 0.4211 - val_loss: 1.3588 - val_acc: 0.4167\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 50s 503ms/step - loss: 1.3065 - acc: 0.4616 - val_loss: 1.4726 - val_acc: 0.4167\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 59s 589ms/step - loss: 1.2456 - acc: 0.5034 - val_loss: 1.3056 - val_acc: 0.5833\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 51s 509ms/step - loss: 1.2044 - acc: 0.5152 - val_loss: 1.4435 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 1.1430 - acc: 0.5530 - val_loss: 1.2836 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 58s 579ms/step - loss: 1.0823 - acc: 0.5737 - val_loss: 1.3022 - val_acc: 0.4167\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 51s 507ms/step - loss: 0.9954 - acc: 0.6137 - val_loss: 1.3384 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "100/100 [==============================] - 56s 559ms/step - loss: 0.9191 - acc: 0.6364 - val_loss: 1.5649 - val_acc: 0.4167\n",
      "Epoch 2/17\n",
      "100/100 [==============================] - 57s 566ms/step - loss: 0.8247 - acc: 0.6919 - val_loss: 1.5214 - val_acc: 0.5000\n",
      "Epoch 3/17\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.7221 - acc: 0.7389 - val_loss: 1.4327 - val_acc: 0.3333\n",
      "Epoch 4/17\n",
      "100/100 [==============================] - 59s 588ms/step - loss: 0.6411 - acc: 0.7741 - val_loss: 1.9297 - val_acc: 0.4167\n",
      "Epoch 5/17\n",
      "100/100 [==============================] - 51s 510ms/step - loss: 0.5018 - acc: 0.8292 - val_loss: 1.6266 - val_acc: 0.4167\n",
      "Epoch 6/17\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 0.3874 - acc: 0.8622 - val_loss: 1.7267 - val_acc: 0.4167\n",
      "Epoch 7/17\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 0.3269 - acc: 0.8879 - val_loss: 2.0073 - val_acc: 0.2500\n",
      "Epoch 8/17\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 0.2252 - acc: 0.9312 - val_loss: 2.7009 - val_acc: 0.4167\n",
      "Epoch 9/17\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 0.1661 - acc: 0.9501 - val_loss: 1.8700 - val_acc: 0.4167\n",
      "Epoch 10/17\n",
      "100/100 [==============================] - 51s 514ms/step - loss: 0.1161 - acc: 0.9701 - val_loss: 2.9843 - val_acc: 0.2500\n",
      "Epoch 11/17\n",
      "100/100 [==============================] - 52s 515ms/step - loss: 0.0910 - acc: 0.9776 - val_loss: 2.7612 - val_acc: 0.4167\n",
      "Epoch 12/17\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 0.0889 - acc: 0.9789 - val_loss: 3.1197 - val_acc: 0.3333\n",
      "Epoch 13/17\n",
      "100/100 [==============================] - 52s 516ms/step - loss: 0.0513 - acc: 0.9885 - val_loss: 3.0777 - val_acc: 0.4167\n",
      "Epoch 14/17\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 0.0533 - acc: 0.9875 - val_loss: 3.0187 - val_acc: 0.4167\n",
      "Epoch 15/17\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.0555 - acc: 0.9870 - val_loss: 2.7373 - val_acc: 0.4167\n",
      "Epoch 16/17\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 0.0325 - acc: 0.9935 - val_loss: 3.2679 - val_acc: 0.5000\n",
      "Epoch 17/17\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 0.0339 - acc: 0.9925 - val_loss: 3.1377 - val_acc: 0.4167\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=17, #acc was improving each epoch, needs more, trying between 15 and 20\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oops, looks like it ran 27 times, val acc is low, most val_image folders of breeds have 2-3 images, more might be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new plan is to run a 5 breed model with train 70% test 15% val 15% rather than the current 90 9 1 \n",
    "#Back to the cleaning_n_prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#70 15 15 achieved, lets try the same breeds in hopes of better val acc with model 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = models.Sequential()\n",
    "model_3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_3.add(layers.Flatten())\n",
    "model_3.add(layers.Dense(64, activation='relu'))\n",
    "model_3.add(layers.Dense(128, activation='relu'))\n",
    "model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_3.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 1.5967 - acc: 0.2590 - val_loss: 1.5728 - val_acc: 0.2604\n",
      "Epoch 2/17\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.5123 - acc: 0.3330 - val_loss: 1.4747 - val_acc: 0.3505\n",
      "Epoch 3/17\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 1.4312 - acc: 0.3666 - val_loss: 1.5666 - val_acc: 0.2945\n",
      "Epoch 4/17\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 1.3662 - acc: 0.4055 - val_loss: 1.4500 - val_acc: 0.3609\n",
      "Epoch 5/17\n",
      "100/100 [==============================] - 61s 608ms/step - loss: 1.3383 - acc: 0.4310 - val_loss: 1.3917 - val_acc: 0.4110\n",
      "Epoch 6/17\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 1.2859 - acc: 0.4705 - val_loss: 1.3970 - val_acc: 0.3956\n",
      "Epoch 7/17\n",
      "100/100 [==============================] - 59s 593ms/step - loss: 1.2298 - acc: 0.4944 - val_loss: 1.4753 - val_acc: 0.3802\n",
      "Epoch 8/17\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 1.1706 - acc: 0.5220 - val_loss: 1.3365 - val_acc: 0.4726\n",
      "Epoch 9/17\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 1.1102 - acc: 0.5665 - val_loss: 1.3869 - val_acc: 0.4978\n",
      "Epoch 10/17\n",
      "100/100 [==============================] - 60s 602ms/step - loss: 1.0477 - acc: 0.5960 - val_loss: 1.3844 - val_acc: 0.4462\n",
      "Epoch 11/17\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 0.9404 - acc: 0.6555 - val_loss: 1.4141 - val_acc: 0.4736\n",
      "Epoch 12/17\n",
      "100/100 [==============================] - 57s 569ms/step - loss: 0.8577 - acc: 0.6930 - val_loss: 1.5177 - val_acc: 0.4257\n",
      "Epoch 13/17\n",
      "100/100 [==============================] - 55s 545ms/step - loss: 0.7072 - acc: 0.7480 - val_loss: 1.6609 - val_acc: 0.4363\n",
      "Epoch 14/17\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.6240 - acc: 0.7861 - val_loss: 1.6038 - val_acc: 0.4670\n",
      "Epoch 15/17\n",
      "100/100 [==============================] - 59s 594ms/step - loss: 0.4664 - acc: 0.8485 - val_loss: 1.8370 - val_acc: 0.4352\n",
      "Epoch 16/17\n",
      "100/100 [==============================] - 52s 520ms/step - loss: 0.3619 - acc: 0.8900 - val_loss: 2.2025 - val_acc: 0.4078\n",
      "Epoch 17/17\n",
      "100/100 [==============================] - 57s 572ms/step - loss: 0.2447 - acc: 0.9275 - val_loss: 2.2904 - val_acc: 0.4308\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=17, #still trying between 15 and 20 this time\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5339999952380867\n",
      "0.4345372494133547\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_3.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm overfitting, is the model is too complex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = models.Sequential()\n",
    "model_4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_4.add(layers.MaxPooling2D((2, 2)))\n",
    "model_4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_4.add(layers.MaxPooling2D((2, 2)))\n",
    "model_4.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_4.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_4.add(layers.Flatten())\n",
    "model_4.add(layers.Dense(64, activation='relu'))\n",
    "model_4.add(layers.Dense(128, activation='relu'))\n",
    "#model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_4.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "#cut some layers in an attempt to fight overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 1.5895 - acc: 0.2670 - val_loss: 1.5444 - val_acc: 0.3637\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 75s 751ms/step - loss: 1.4508 - acc: 0.3890 - val_loss: 1.3995 - val_acc: 0.4846\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 1.2930 - acc: 0.4825 - val_loss: 1.4899 - val_acc: 0.3721\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 1.1475 - acc: 0.5540 - val_loss: 1.3800 - val_acc: 0.4275\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 47s 466ms/step - loss: 0.9740 - acc: 0.6535 - val_loss: 1.4785 - val_acc: 0.4011\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 47s 471ms/step - loss: 0.8187 - acc: 0.7310 - val_loss: 1.5285 - val_acc: 0.3923\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 56s 565ms/step - loss: 0.6316 - acc: 0.7960 - val_loss: 2.0100 - val_acc: 0.3799\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 0.4900 - acc: 0.8525 - val_loss: 1.8302 - val_acc: 0.4143\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 0.3464 - acc: 0.9115 - val_loss: 2.1556 - val_acc: 0.4099\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 47s 469ms/step - loss: 0.2265 - acc: 0.9530 - val_loss: 2.3513 - val_acc: 0.4165\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_4.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10, #10 for now\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine, I'll dumb it down even more\n",
    "model_5 = models.Sequential()\n",
    "model_5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_5.add(layers.MaxPooling2D((2, 2)))\n",
    "model_5.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_5.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_4.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "#model_4.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_5.add(layers.Flatten())\n",
    "model_5.add(layers.Dense(64, activation='relu'))\n",
    "#model_4.add(layers.Dense(128, activation='relu'))\n",
    "#model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_5.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_5.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 40s 395ms/step - loss: 1.6081 - acc: 0.2605 - val_loss: 1.6790 - val_acc: 0.1791\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 47s 470ms/step - loss: 1.4357 - acc: 0.4250 - val_loss: 1.4522 - val_acc: 0.4220\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 1.2467 - acc: 0.5326 - val_loss: 1.3751 - val_acc: 0.4253\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 1.0825 - acc: 0.6225 - val_loss: 1.4232 - val_acc: 0.3866\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 49s 490ms/step - loss: 0.9227 - acc: 0.6845 - val_loss: 1.3858 - val_acc: 0.4088\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 38s 375ms/step - loss: 0.7724 - acc: 0.7675 - val_loss: 1.5718 - val_acc: 0.3901\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 0.6457 - acc: 0.8120 - val_loss: 1.6193 - val_acc: 0.3330\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.5291 - acc: 0.8640 - val_loss: 1.6002 - val_acc: 0.3944\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 45s 452ms/step - loss: 0.4070 - acc: 0.9080 - val_loss: 1.6493 - val_acc: 0.3857\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 38s 379ms/step - loss: 0.3316 - acc: 0.9275 - val_loss: 1.6798 - val_acc: 0.3538\n"
     ]
    }
   ],
   "source": [
    "history_6 = model_5.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9381213243335957\n",
      "0.3261851013951323\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_5.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added flips now to the data gen, let's see if it helps\n",
    "model_6 = models.Sequential()\n",
    "model_6.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_6.add(layers.MaxPooling2D((2, 2)))\n",
    "model_6.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_6.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_4.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "#model_4.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_6.add(layers.Flatten())\n",
    "model_6.add(layers.Dense(32, activation='relu'))#changed to 32 to further simplify\n",
    "#model_4.add(layers.Dense(128, activation='relu'))\n",
    "#model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_6.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_6.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 1.5937 - acc: 0.2655 - val_loss: 1.5568 - val_acc: 0.3396\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 1.5162 - acc: 0.3360 - val_loss: 1.5545 - val_acc: 0.3308\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 41s 414ms/step - loss: 1.4701 - acc: 0.3725 - val_loss: 1.4976 - val_acc: 0.4033\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 1.4395 - acc: 0.3865 - val_loss: 1.4972 - val_acc: 0.3698\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 59s 590ms/step - loss: 1.4204 - acc: 0.3980 - val_loss: 1.5011 - val_acc: 0.3890\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 72s 720ms/step - loss: 1.3845 - acc: 0.4185 - val_loss: 1.5664 - val_acc: 0.3978\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 43s 434ms/step - loss: 1.3886 - acc: 0.4120 - val_loss: 1.4869 - val_acc: 0.3912\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 1.3633 - acc: 0.4210 - val_loss: 1.5640 - val_acc: 0.3899\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 47s 471ms/step - loss: 1.3461 - acc: 0.4370 - val_loss: 1.4785 - val_acc: 0.3879\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 1.3241 - acc: 0.4500 - val_loss: 1.5123 - val_acc: 0.4077\n"
     ]
    }
   ],
   "source": [
    "history_7 = model_6.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.474687071470859\n",
      "0.3679458259459812\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_6.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added flips now to the data gen, let's see if it helps\n",
    "model_7 = models.Sequential()\n",
    "model_7.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))#imput layer\n",
    "model_7.add(layers.MaxPooling2D((2, 2)))\n",
    "model_7.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_7.add(layers.MaxPooling2D((2, 2)))\n",
    "model_7.add(layers.Conv2D(128, (3, 3), activation='relu'))#brough another Convolution layer back\n",
    "model_7.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_7.add(layers.Flatten())\n",
    "model_7.add(layers.Dense(64, activation='relu'))#changed to back to 64 to add complexity\n",
    "#model_4.add(layers.Dense(128, activation='relu'))\n",
    "#model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_7.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_7.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 1.5441 - acc: 0.2970 - val_loss: 1.4327 - val_acc: 0.4220\n",
      "Epoch 2/12\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.4300 - acc: 0.3855 - val_loss: 1.4183 - val_acc: 0.4145\n",
      "Epoch 3/12\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 1.3599 - acc: 0.4245 - val_loss: 1.3667 - val_acc: 0.4143\n",
      "Epoch 4/12\n",
      "100/100 [==============================] - 56s 564ms/step - loss: 1.3216 - acc: 0.4470 - val_loss: 1.4310 - val_acc: 0.3725\n",
      "Epoch 5/12\n",
      "100/100 [==============================] - 48s 477ms/step - loss: 1.2648 - acc: 0.4935 - val_loss: 1.3885 - val_acc: 0.4132\n",
      "Epoch 6/12\n",
      "100/100 [==============================] - 47s 471ms/step - loss: 1.2265 - acc: 0.5161 - val_loss: 1.3714 - val_acc: 0.4179\n",
      "Epoch 7/12\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 1.1906 - acc: 0.5335 - val_loss: 1.3785 - val_acc: 0.4066\n",
      "Epoch 8/12\n",
      "100/100 [==============================] - 48s 479ms/step - loss: 1.1434 - acc: 0.5555 - val_loss: 1.4491 - val_acc: 0.4176\n",
      "Epoch 9/12\n",
      "100/100 [==============================] - 48s 475ms/step - loss: 1.1105 - acc: 0.5675 - val_loss: 1.4022 - val_acc: 0.3934\n",
      "Epoch 10/12\n",
      "100/100 [==============================] - 52s 519ms/step - loss: 1.0609 - acc: 0.5970 - val_loss: 1.3862 - val_acc: 0.4223\n",
      "Epoch 11/12\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.0397 - acc: 0.6075 - val_loss: 1.5388 - val_acc: 0.4121\n",
      "Epoch 12/12\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 0.9755 - acc: 0.6275 - val_loss: 1.4353 - val_acc: 0.4154\n"
     ]
    }
   ],
   "source": [
    "history_8 = model_7.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=12, #just a little more than last time\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4178522961362423\n",
      "0.4521337918069261\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_7.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,699,269\n",
      "Trainable params: 1,699,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray-scaled all images imput shape changed to 1 as no longer rgb\n",
    "model_8 = models.Sequential()\n",
    "model_8.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))\n",
    "model_8.add(layers.MaxPooling2D((2, 2)))\n",
    "model_8.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_8.add(layers.MaxPooling2D((2, 2)))\n",
    "model_8.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_8.add(layers.MaxPooling2D((2, 2)))\n",
    "#model_3.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model_3.add(layers.MaxPooling2D((2, 2)))\n",
    "model_8.add(layers.Flatten())\n",
    "model_8.add(layers.Dense(64, activation='relu'))\n",
    "model_8.add(layers.Dense(128, activation='relu'))#brough anohter dense layer back\n",
    "#model_3.add(layers.Dense(256, activation='relu'))\n",
    "model_8.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_8.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 50s 498ms/step - loss: 1.5996 - acc: 0.2440 - val_loss: 1.5954 - val_acc: 0.2165\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 1.5413 - acc: 0.3190 - val_loss: 1.5303 - val_acc: 0.3648\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 56s 563ms/step - loss: 1.4851 - acc: 0.3595 - val_loss: 1.5316 - val_acc: 0.3564\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 47s 471ms/step - loss: 1.4615 - acc: 0.3660 - val_loss: 1.5455 - val_acc: 0.3714\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 1.4479 - acc: 0.3795 - val_loss: 1.5470 - val_acc: 0.2934\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 1.4358 - acc: 0.3880 - val_loss: 1.5278 - val_acc: 0.3615\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 1.4121 - acc: 0.3995 - val_loss: 1.5121 - val_acc: 0.3084\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 1.3983 - acc: 0.4060 - val_loss: 1.5041 - val_acc: 0.3571\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 51s 515ms/step - loss: 1.3688 - acc: 0.4189 - val_loss: 1.5212 - val_acc: 0.3593\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 1.3671 - acc: 0.4201 - val_loss: 1.5085 - val_acc: 0.3484\n"
     ]
    }
   ],
   "source": [
    "history_9 = model_8.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4444455312014164\n",
      "0.4232505655786523\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_8.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)#we're underfitting again, time to up the complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 = models.Sequential()\n",
    "model_9.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))\n",
    "model_9.add(layers.MaxPooling2D((2, 2)))\n",
    "model_9.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_9.add(layers.MaxPooling2D((2, 2)))\n",
    "model_9.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_9.add(layers.MaxPooling2D((2, 2)))\n",
    "model_9.add(layers.Conv2D(256, (3, 3), activation='relu'))#brough another Convolution layer back\n",
    "model_9.add(layers.MaxPooling2D((2, 2)))\n",
    "model_9.add(layers.Flatten())\n",
    "model_9.add(layers.Dense(64, activation='relu'))\n",
    "model_9.add(layers.Dense(128, activation='relu'))\n",
    "model_9.add(layers.Dense(256, activation='relu'))#brough another dense layer layer back\n",
    "model_9.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_9.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 1.6040 - acc: 0.2265 - val_loss: 1.6019 - val_acc: 0.2045\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 54s 536ms/step - loss: 1.5750 - acc: 0.2870 - val_loss: 1.5407 - val_acc: 0.3582\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 79s 792ms/step - loss: 1.5127 - acc: 0.3525 - val_loss: 1.5356 - val_acc: 0.3495\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 92s 918ms/step - loss: 1.4828 - acc: 0.3440 - val_loss: 1.5104 - val_acc: 0.3560\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s 651ms/step - loss: 1.4727 - acc: 0.3590 - val_loss: 1.5345 - val_acc: 0.3017\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 75s 747ms/step - loss: 1.4568 - acc: 0.3635 - val_loss: 1.5388 - val_acc: 0.3374\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 55s 554ms/step - loss: 1.4484 - acc: 0.3865 - val_loss: 1.6060 - val_acc: 0.3549\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 66s 658ms/step - loss: 1.4379 - acc: 0.3805 - val_loss: 1.5184 - val_acc: 0.3703\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 74s 743ms/step - loss: 1.4384 - acc: 0.3821 - val_loss: 1.5039 - val_acc: 0.3899\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 85s 848ms/step - loss: 1.4028 - acc: 0.4030 - val_loss: 1.5001 - val_acc: 0.3725\n"
     ]
    }
   ],
   "source": [
    "history_10 = model_9.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = models.Sequential()\n",
    "model_a.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))\n",
    "model_a.add(layers.MaxPooling2D((2, 2)))\n",
    "model_a.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_a.add(layers.MaxPooling2D((2, 2)))\n",
    "model_a.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_a.add(layers.MaxPooling2D((2, 2)))\n",
    "model_a.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_a.add(layers.MaxPooling2D((2, 2)))\n",
    "model_a.add(layers.Conv2D(256, (3, 3), activation='relu'))#brough another Convolution layer back\n",
    "model_a.add(layers.MaxPooling2D((2, 2)))\n",
    "model_a.add(layers.Flatten())\n",
    "model_a.add(layers.Dense(64, activation='relu'))\n",
    "model_a.add(layers.Dense(64, activation='relu'))\n",
    "model_a.add(layers.Dense(128, activation='relu'))\n",
    "model_a.add(layers.Dense(256, activation='relu'))#brough another dense layer layer back\n",
    "model_a.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model_a.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "100/100 [==============================] - 84s 840ms/step - loss: 1.6017 - acc: 0.2249 - val_loss: 1.6061 - val_acc: 0.1923\n",
      "Epoch 2/17\n",
      "100/100 [==============================] - 94s 942ms/step - loss: 1.5687 - acc: 0.2980 - val_loss: 1.5636 - val_acc: 0.2749\n",
      "Epoch 3/17\n",
      "100/100 [==============================] - 109s 1s/step - loss: 1.5206 - acc: 0.3305 - val_loss: 1.5276 - val_acc: 0.3286\n",
      "Epoch 4/17\n",
      "100/100 [==============================] - 68s 684ms/step - loss: 1.4965 - acc: 0.3465 - val_loss: 1.5554 - val_acc: 0.3275\n",
      "Epoch 5/17\n",
      "100/100 [==============================] - 65s 653ms/step - loss: 1.4844 - acc: 0.3565 - val_loss: 1.5631 - val_acc: 0.3363\n",
      "Epoch 6/17\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 1.4666 - acc: 0.3625 - val_loss: 1.5143 - val_acc: 0.3855\n",
      "Epoch 7/17\n",
      "100/100 [==============================] - 79s 789ms/step - loss: 1.4720 - acc: 0.3625 - val_loss: 1.5167 - val_acc: 0.3890\n",
      "Epoch 8/17\n",
      "100/100 [==============================] - 84s 838ms/step - loss: 1.4568 - acc: 0.3675 - val_loss: 1.4874 - val_acc: 0.3758\n",
      "Epoch 9/17\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 1.4490 - acc: 0.3600 - val_loss: 1.4875 - val_acc: 0.3956\n",
      "Epoch 10/17\n",
      "100/100 [==============================] - 67s 668ms/step - loss: 1.4324 - acc: 0.3710 - val_loss: 1.4983 - val_acc: 0.3844\n",
      "Epoch 11/17\n",
      "100/100 [==============================] - 58s 578ms/step - loss: 1.4232 - acc: 0.3770 - val_loss: 1.5033 - val_acc: 0.4033\n",
      "Epoch 12/17\n",
      "100/100 [==============================] - 67s 673ms/step - loss: 1.4207 - acc: 0.3870 - val_loss: 1.5342 - val_acc: 0.3934\n",
      "Epoch 13/17\n",
      "100/100 [==============================] - 55s 546ms/step - loss: 1.3981 - acc: 0.4050 - val_loss: 1.4861 - val_acc: 0.4165\n",
      "Epoch 14/17\n",
      "100/100 [==============================] - 56s 555ms/step - loss: 1.3852 - acc: 0.4085 - val_loss: 1.4537 - val_acc: 0.4480\n",
      "Epoch 15/17\n",
      "100/100 [==============================] - 57s 572ms/step - loss: 1.3596 - acc: 0.4285 - val_loss: 1.5142 - val_acc: 0.3769\n",
      "Epoch 16/17\n",
      "100/100 [==============================] - 51s 505ms/step - loss: 1.3449 - acc: 0.4434 - val_loss: 1.5311 - val_acc: 0.3692\n",
      "Epoch 17/17\n",
      "100/100 [==============================] - 59s 585ms/step - loss: 1.3358 - acc: 0.4320 - val_loss: 1.4567 - val_acc: 0.3967\n"
     ]
    }
   ],
   "source": [
    "history_a = model_a.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=17, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41400719005152\n",
      "0.3837471809196149\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_a.evaluate_generator(test_generator, steps=50)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
